{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import codecs\n",
    "import matplotlib as mpl\n",
    "from matplotlib.cm import get_cmap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "remove = ('headers', 'footers', 'quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_dict = {k:v for k, v in enumerate(data_train.data)}\n",
    "doc_cat = {k:v for k, v in enumerate(data_train.target)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hasher = HashingVectorizer(stop_words='english', alternate_sign=False, norm=None, binary=False)\n",
    "# vectorizer = make_pipeline(hasher, TfidfTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 2034, n_features: 26576\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26576\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names() \n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26566</th>\n",
       "      <th>26567</th>\n",
       "      <th>26568</th>\n",
       "      <th>26569</th>\n",
       "      <th>26570</th>\n",
       "      <th>26571</th>\n",
       "      <th>26572</th>\n",
       "      <th>26573</th>\n",
       "      <th>26574</th>\n",
       "      <th>26575</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   ...    26566  26567  26568  26569  26570  26571  26572  26573  26574  26575  \n",
       "0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[1 rows x 26576 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2034x26576 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 133634 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n",
      "          feature     tfidf\n",
      "0          koresh  0.260513\n",
      "1      delusional  0.246107\n",
      "2        deranged  0.246107\n",
      "3      fruitcakes  0.246107\n",
      "4         barring  0.246107\n",
      "5           mania  0.246107\n",
      "6           circa  0.233515\n",
      "7      neccessary  0.233515\n",
      "8         fanatic  0.224582\n",
      "9         satisfy  0.211990\n",
      "10          jones  0.211990\n",
      "11  demonstrating  0.207203\n",
      "12     corruption  0.207203\n",
      "13           nope  0.193167\n",
      "14      centuries  0.179649\n",
      "15       contrary  0.171642\n",
      "16          bunch  0.171642\n",
      "17          folks  0.163063\n",
      "18           evil  0.153863\n",
      "19            jim  0.152310\n",
      "20       children  0.143188\n",
      "21           1993  0.132338\n",
      "22       evidence  0.131166\n",
      "23         simply  0.129669\n",
      "24        thought  0.117693\n"
     ]
    }
   ],
   "source": [
    "print(categories[doc_cat.get(1)])\n",
    "print(top_feats_in_doc(X_train, feature_names, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "feature_tfidf_wts = top_feats_in_doc(X_train, feature_names, 1)\n",
    "print(type(feature_tfidf_wts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = feature_tfidf_wts.set_index('feature').to_dict()['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034,)\n"
     ]
    }
   ],
   "source": [
    "type(data_train.data[1])\n",
    "print(data_train.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_feats_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = top_feats_by_class(X_train, data_train.target, features=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, to_lower=True, norm_num=False):\n",
    "    # remove links (other html crap is assumed to be removed by bs)\n",
    "    text = re.sub(r\"http(s)?://\\S*\", \" \", text)  \n",
    "    if to_lower:\n",
    "        text = text.lower()\n",
    "    if norm_num:\n",
    "        text = re.sub(r\"[0-9]\", \"1\", text)  # normalize numbers\n",
    "    # clean out non-alphabet characters and normalize whitespace\n",
    "    text = re.sub(r\"[^A-Za-z0-9-]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scores2html(text, scores, fname='testfile', metainf='', pos_clr_name='Blues', \n",
    "                neg_clr_name='Reds', highlight_oov=False):\n",
    "    \"\"\"\n",
    "    Reference: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    Based on the original text and relevance scores, generate a html doc highlighting positive / negative words\n",
    "    Inputs:\n",
    "        - text: the raw text in which the words should be highlighted\n",
    "        - scores: a dictionary with {word: score} or a list with tuples [(word, score)]\n",
    "        - fname: the name (path) of the file\n",
    "        - metainf: an optional string which will be added at the top of the file (e.g. true class of the document)\n",
    "        - highlight_oov: if True, out-of-vocabulary words will be highlighted in yellow (default False)\n",
    "    Saves the visualization in 'fname.html' (you probably want to make this a whole path to not clutter your main directory...)\n",
    "    \"\"\"\n",
    "    # colormaps\n",
    "    cmap_pos = get_cmap(pos_clr_name)\n",
    "    cmap_neg = get_cmap(neg_clr_name)\n",
    "    norm = mpl.colors.Normalize(0., 1.)\n",
    "\n",
    "#     if not isinstance(text, unicode):\n",
    "#         text = text.decode(\"utf-8\")\n",
    "\n",
    "    # normalize score by absolute max value\n",
    "    if isinstance(scores, dict):\n",
    "        N = np.max(np.abs(list(scores.values())))\n",
    "        scores_dict = {word: scores[word] / N for word in scores}\n",
    "        # transform dict into word list with scores\n",
    "        scores = []\n",
    "        for word in re.findall(r'[\\w-]+', text, re.UNICODE):\n",
    "            word_pp = preprocess_text(word)\n",
    "            if word_pp in scores_dict:\n",
    "                scores.append((word, scores_dict[word_pp]))\n",
    "            else:\n",
    "                scores.append((word, None))\n",
    "    else:\n",
    "        N = np.max(np.abs([t[1] for t in scores if t[1] is not None]))\n",
    "        scores = [(w, s / N) if s is not None else (w, None) for w, s in scores]\n",
    "\n",
    "    htmlstr = u'<body><div style=\"white-space: pre-wrap; font-family: monospace;\">'\n",
    "    if metainf:\n",
    "        htmlstr += '%s\\n\\n' % metainf\n",
    "    resttext = text\n",
    "    for word, score in scores:\n",
    "        # was anything before the identified word? add it unchanged to the html\n",
    "        htmlstr += resttext[:resttext.find(word)]\n",
    "        # cut off the identified word\n",
    "        resttext = resttext[resttext.find(word) + len(word):]\n",
    "        # get the colorcode of the word\n",
    "        rgbac = (1., 1., 0.)  # for unknown words\n",
    "        if highlight_oov:\n",
    "            alpha = 0.3\n",
    "        else:\n",
    "            alpha = 0.\n",
    "        if score is not None:\n",
    "            if score < 0:\n",
    "                rgbac = cmap_neg(norm(-score))\n",
    "            else:\n",
    "                rgbac = cmap_pos(norm(score))\n",
    "            alpha = 0.5\n",
    "        htmlstr += u'<span style=\"background-color: rgba(%i, %i, %i, %.1f)\">%s</span>'\\\n",
    "            % (round(255 * rgbac[0]), round(255 * rgbac[1]), round(255 * rgbac[2]), alpha, word)\n",
    "    # after the last word, add the rest of the text\n",
    "    htmlstr += resttext\n",
    "    htmlstr += u'</div></body>'\n",
    "    with codecs.open('%s.html' % fname, 'w', encoding='utf8') as f:\n",
    "        f.write(htmlstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores2html(data_train.data[1], scores, highlight_oov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n"
     ]
    }
   ],
   "source": [
    "print(data_train.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<body><div style=\"white-space: pre-wrap; font-family: monospace;\">\n",
       "\n",
       "<span style=\"background-color: rgba(255, 255, 0, 0.3)\">Seems</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">be</span>, <span style=\"background-color: rgba(8, 62, 129, 0.5)\">barring</span> <span style=\"background-color: rgba(106, 174, 214, 0.5)\">evidence</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">the</span> <span style=\"background-color: rgba(57, 137, 193, 0.5)\">contrary</span>, <span style=\"background-color: rgba(255, 255, 0, 0.3)\">that</span> <span style=\"background-color: rgba(8, 48, 107, 0.5)\">Koresh</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">was</span> <span style=\"background-color: rgba(108, 174, 214, 0.5)\">simply</span>\n",
       "<span style=\"background-color: rgba(255, 255, 0, 0.3)\">another</span> <span style=\"background-color: rgba(8, 62, 129, 0.5)\">deranged</span> <span style=\"background-color: rgba(10, 84, 158, 0.5)\">fanatic</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">who</span> <span style=\"background-color: rgba(127, 185, 218, 0.5)\">thought</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">it</span> <span style=\"background-color: rgba(8, 75, 147, 0.5)\">neccessary</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">take</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">a</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">whole</span> <span style=\"background-color: rgba(57, 137, 193, 0.5)\">bunch</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">of</span>\n",
       "<span style=\"background-color: rgba(65, 145, 198, 0.5)\">folks</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">with</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">him</span>, <span style=\"background-color: rgba(91, 163, 208, 0.5)\">children</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">and</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">all</span>, <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(20, 96, 168, 0.5)\">satisfy</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">his</span> <span style=\"background-color: rgba(8, 62, 129, 0.5)\">delusional</span> <span style=\"background-color: rgba(8, 62, 129, 0.5)\">mania</span>. <span style=\"background-color: rgba(79, 155, 203, 0.5)\">Jim</span>\n",
       "<span style=\"background-color: rgba(20, 96, 168, 0.5)\">Jones</span>, <span style=\"background-color: rgba(8, 75, 147, 0.5)\">circa</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">1993</span>.\n",
       "\n",
       "\n",
       "<span style=\"background-color: rgba(35, 115, 182, 0.5)\">Nope</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">-</span> <span style=\"background-color: rgba(8, 62, 129, 0.5)\">fruitcakes</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">like</span> <span style=\"background-color: rgba(8, 48, 107, 0.5)\">Koresh</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">have</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">been</span> <span style=\"background-color: rgba(24, 101, 172, 0.5)\">demonstrating</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">such</span> <span style=\"background-color: rgba(77, 153, 202, 0.5)\">evil</span> <span style=\"background-color: rgba(24, 101, 172, 0.5)\">corruption</span>\n",
       "<span style=\"background-color: rgba(255, 255, 0, 0.3)\">for</span> <span style=\"background-color: rgba(49, 129, 189, 0.5)\">centuries</span>.</div></body>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_in_notebook():\n",
    "    from IPython.core.display import display, HTML\n",
    "    return HTML('./testfile.html')\n",
    "show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build a classifier and see if you can visualize feature contribution ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=50, penalty=\"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=50,\n",
       "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_train.target\n",
    "clf.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24152341,  0.        ,  0.        , ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(feature_names))\n",
    "clf.predict(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [(a,b) for a, b in zip(feature_names, np.squeeze(clf.coef_[0]))]\n",
    "clf_wts_df = pd.DataFrame(temp)\n",
    "clf_wts_df.columns = ['feature', 'wts']\n",
    "clf_dict = clf_wts_df.set_index('feature').to_dict()['wts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<body><div style=\"white-space: pre-wrap; font-family: monospace;\">\n",
       "\n",
       "<span style=\"background-color: rgba(255, 255, 0, 0.3)\">Seems</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">be</span>, <span style=\"background-color: rgba(247, 251, 255, 0.5)\">barring</span> <span style=\"background-color: rgba(227, 238, 249, 0.5)\">evidence</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">the</span> <span style=\"background-color: rgba(254, 216, 199, 0.5)\">contrary</span>, <span style=\"background-color: rgba(255, 255, 0, 0.3)\">that</span> <span style=\"background-color: rgba(220, 234, 246, 0.5)\">Koresh</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">was</span> <span style=\"background-color: rgba(211, 228, 243, 0.5)\">simply</span>\n",
       "<span style=\"background-color: rgba(255, 255, 0, 0.3)\">another</span> <span style=\"background-color: rgba(247, 251, 255, 0.5)\">deranged</span> <span style=\"background-color: rgba(255, 245, 240, 0.5)\">fanatic</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">who</span> <span style=\"background-color: rgba(223, 236, 247, 0.5)\">thought</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">it</span> <span style=\"background-color: rgba(255, 237, 229, 0.5)\">neccessary</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">take</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">a</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">whole</span> <span style=\"background-color: rgba(247, 251, 255, 0.5)\">bunch</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">of</span>\n",
       "<span style=\"background-color: rgba(254, 232, 222, 0.5)\">folks</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">with</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">him</span>, <span style=\"background-color: rgba(252, 132, 100, 0.5)\">children</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">and</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">all</span>, <span style=\"background-color: rgba(255, 255, 0, 0.3)\">to</span> <span style=\"background-color: rgba(247, 251, 255, 0.5)\">satisfy</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">his</span> <span style=\"background-color: rgba(247, 251, 255, 0.5)\">delusional</span> <span style=\"background-color: rgba(247, 251, 255, 0.5)\">mania</span>. <span style=\"background-color: rgba(190, 216, 236, 0.5)\">Jim</span>\n",
       "<span style=\"background-color: rgba(247, 251, 255, 0.5)\">Jones</span>, <span style=\"background-color: rgba(247, 251, 255, 0.5)\">circa</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">1993</span>.\n",
       "\n",
       "\n",
       "<span style=\"background-color: rgba(196, 218, 238, 0.5)\">Nope</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">-</span> <span style=\"background-color: rgba(247, 251, 255, 0.5)\">fruitcakes</span> <span style=\"background-color: rgba(254, 225, 212, 0.5)\">like</span> <span style=\"background-color: rgba(220, 234, 246, 0.5)\">Koresh</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">have</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">been</span> <span style=\"background-color: rgba(254, 233, 223, 0.5)\">demonstrating</span> <span style=\"background-color: rgba(255, 255, 0, 0.3)\">such</span> <span style=\"background-color: rgba(253, 212, 194, 0.5)\">evil</span> <span style=\"background-color: rgba(223, 236, 247, 0.5)\">corruption</span>\n",
       "<span style=\"background-color: rgba(255, 255, 0, 0.3)\">for</span> <span style=\"background-color: rgba(252, 176, 149, 0.5)\">centuries</span>.</div></body>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2html(data_train.data[1], clf_dict, highlight_oov=True)\n",
    "show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
