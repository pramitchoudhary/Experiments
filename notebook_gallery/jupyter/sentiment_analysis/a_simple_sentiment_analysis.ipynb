{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement: Classify text as +ve or -ve sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reference: http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "# Lets specify some positive tweets for evaluation purpose\n",
    "pos_tweets = [('I love this car', 'positive'), ('This view is amazing', 'positive'), \n",
    "              ('I feel great this morning', 'positive'), ('I am so excited about the concert', 'positive'),\n",
    "              ('He is my best friend', 'positive'), ('The beer is good', 'positive'), \n",
    "              ('I do love ice-cream', 'positive'), ('morning is good', 'positive'), ('welcome morning', 'positive')]\n",
    "\n",
    "# Similary some negative tweets\n",
    "neg_tweets = [('I do not like this car', 'negative'), ('This view is horrible', 'negative'), \n",
    "              ('I am not looking forward to the party', 'negative'),\n",
    "              ('He is my enemy', 'negative'), ('very annoying', 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      0         1\n",
      "0                     [love, this, car]  positive\n",
      "1                 [this, view, amazing]  positive\n",
      "2          [feel, great, this, morning]  positive\n",
      "3        [excited, about, the, concert]  positive\n",
      "4                        [best, friend]  positive\n",
      "5                     [the, beer, good]  positive\n",
      "6                     [love, ice-cream]  positive\n",
      "7                       [morning, good]  positive\n",
      "8                    [welcome, morning]  positive\n",
      "9                [not, like, this, car]  negative\n",
      "10               [this, view, horrible]  negative\n",
      "11  [not, looking, forward, the, party]  negative\n",
      "12                              [enemy]  negative\n",
      "13                     [very, annoying]  negative\n"
     ]
    }
   ],
   "source": [
    "# 1. Transform the array of positive and negative tweets to a tuple2 (tweet, sentiment)\n",
    "# 2. Filtered some stop words, where word length < 3\n",
    "tweets = []\n",
    "for (words, sentiment) in pos_tweets + neg_tweets:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "    tweets.append((words_filtered, sentiment))\n",
    "print(pd.DataFrame(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "      # append words to a list\n",
    "      all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    # make use of nltk.FreqDist function to compute TF\n",
    "    w_l = nltk.FreqDist(wordlist)\n",
    "    return w_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(tweets))\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in the corpus: ['about' 'amazing' 'annoying' 'beer' 'best' 'car' 'concert' 'enemy'\n",
      " 'excited' 'feel' 'forward' 'friend' 'good' 'great' 'horrible' 'ice-cream'\n",
      " 'like' 'looking' 'love' 'morning' 'not' 'party' 'the' 'this' 'very' 'view'\n",
      " 'welcome']\n",
      "Count of unique words in corpus: 27\n",
      "            0  1\n",
      "0        this  5\n",
      "1     morning  3\n",
      "2         the  3\n",
      "3        love  2\n",
      "4        good  2\n",
      "5         not  2\n",
      "6         car  2\n",
      "7        view  2\n",
      "8     concert  1\n",
      "9        feel  1\n",
      "10  ice-cream  1\n",
      "11   annoying  1\n",
      "12       best  1\n",
      "13    amazing  1\n",
      "14    looking  1\n",
      "15       beer  1\n",
      "16   horrible  1\n",
      "17    forward  1\n",
      "18      party  1\n",
      "19    excited  1\n",
      "20     friend  1\n",
      "21       very  1\n",
      "22    welcome  1\n",
      "23      about  1\n",
      "24      enemy  1\n",
      "25      great  1\n",
      "26       like  1\n"
     ]
    }
   ],
   "source": [
    "unique_word_list = np.unique(get_words_in_tweets(tweets))\n",
    "print('Unique words in the corpus: {}'.format(unique_word_list))\n",
    "print('Count of unique words in corpus: {}'.format(len(unique_word_list)))\n",
    "print(pd.DataFrame(word_features.most_common(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'contains(looking)': False, 'contains(not)': False, 'contains(excited)': False, 'contains(view)': False, 'contains(welcome)': False, 'contains(forward)': False, 'contains(ice-cream)': False, 'contains(love)': True, 'contains(enemy)': False, 'contains(very)': False, 'contains(horrible)': False, 'contains(beer)': False, 'contains(party)': False, 'contains(about)': False, 'contains(concert)': False, 'contains(feel)': False, 'contains(like)': False, 'contains(annoying)': False, 'contains(great)': False, 'contains(the)': False, 'contains(friend)': False, 'contains(morning)': False, 'contains(best)': False, 'contains(good)': False, 'contains(this)': True, 'contains(car)': True, 'contains(amazing)': False}, 'positive'), ({'contains(looking)': False, 'contains(not)': False, 'contains(excited)': False, 'contains(view)': True, 'contains(welcome)': False, 'contains(forward)': False, 'contains(ice-cream)': False, 'contains(love)': False, 'contains(enemy)': False, 'contains(very)': False, 'contains(horrible)': False, 'contains(beer)': False, 'contains(party)': False, 'contains(about)': False, 'contains(concert)': False, 'contains(feel)': False, 'contains(like)': False, 'contains(annoying)': False, 'contains(great)': False, 'contains(the)': False, 'contains(friend)': False, 'contains(morning)': False, 'contains(best)': False, 'contains(good)': False, 'contains(this)': True, 'contains(car)': False, 'contains(amazing)': True}, 'positive'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "       contains(concert) = True           negati : positi =      1.7 : 1.0\n",
      "           contains(car) = True           negati : positi =      1.7 : 1.0\n",
      "          contains(view) = True           negati : positi =      1.7 : 1.0\n",
      "           contains(not) = False          positi : negati =      1.6 : 1.0\n",
      "       contains(morning) = False          negati : positi =      1.4 : 1.0\n",
      "          contains(like) = False          positi : negati =      1.3 : 1.0\n",
      "      contains(annoying) = False          positi : negati =      1.3 : 1.0\n",
      "       contains(looking) = False          positi : negati =      1.3 : 1.0\n",
      "         contains(enemy) = False          positi : negati =      1.3 : 1.0\n",
      "       contains(forward) = False          positi : negati =      1.3 : 1.0\n",
      "          contains(very) = False          positi : negati =      1.3 : 1.0\n",
      "      contains(horrible) = False          positi : negati =      1.3 : 1.0\n",
      "          contains(good) = False          negati : positi =      1.2 : 1.0\n",
      "          contains(love) = False          negati : positi =      1.2 : 1.0\n",
      "          contains(this) = True           negati : positi =      1.2 : 1.0\n",
      "       contains(concert) = False          positi : negati =      1.1 : 1.0\n",
      "           contains(car) = False          positi : negati =      1.1 : 1.0\n",
      "          contains(view) = False          positi : negati =      1.1 : 1.0\n",
      "          contains(this) = False          positi : negati =      1.1 : 1.0\n",
      "          contains(beer) = False          negati : positi =      1.1 : 1.0\n",
      "       contains(excited) = False          negati : positi =      1.1 : 1.0\n",
      "         contains(about) = False          negati : positi =      1.1 : 1.0\n",
      "     contains(ice-cream) = False          negati : positi =      1.1 : 1.0\n",
      "       contains(welcome) = False          negati : positi =      1.1 : 1.0\n",
      "       contains(amazing) = False          negati : positi =      1.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.show_most_informative_features(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0      1\n",
      "0     contains(looking)  False\n",
      "1         contains(not)  False\n",
      "2     contains(excited)  False\n",
      "3        contains(view)  False\n",
      "4     contains(welcome)  False\n",
      "5     contains(forward)  False\n",
      "6   contains(ice-cream)  False\n",
      "7        contains(love)  False\n",
      "8       contains(enemy)  False\n",
      "9        contains(very)  False\n",
      "10   contains(horrible)  False\n",
      "11       contains(beer)  False\n",
      "12      contains(about)  False\n",
      "13    contains(concert)  False\n",
      "14       contains(feel)  False\n",
      "15       contains(like)  False\n",
      "16   contains(annoying)  False\n",
      "17      contains(great)  False\n",
      "18        contains(the)  False\n",
      "19     contains(friend)   True\n",
      "20    contains(morning)  False\n",
      "21       contains(best)  False\n",
      "22       contains(good)  False\n",
      "23       contains(this)  False\n",
      "24        contains(car)  False\n",
      "25    contains(amazing)  False\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# A positive example\n",
    "tweet = 'Larry is my friend'\n",
    "transformed_features = extract_features(tweet.split())\n",
    "print (pd.DataFrame(transformed_features.items()))\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "# A failed example\n",
    "tweet = 'Your song is annoying'\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "# Add the words annoying to the list and repeat\n",
    "tweet = 'Your song is annoying'\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "tweet = 'love the summers'\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "tweet = 'hate the winters'\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "tweet = 'review on Black Mirror'\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "tweet = 'i got a bad grade'\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "tweet = 'This is the best course ever'\n",
    "print classifier.classify(extract_features(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Persist the model for usage using pickle\n",
    "# Reference: https://docs.python.org/2/library/pickle.html\n",
    "serialized_classifier = open(\"nb_sentiment.pickle\",\"wb\")\n",
    "pickle.dump(classifier, serialized_classifier)\n",
    "serialized_classifier.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
