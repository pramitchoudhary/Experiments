{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential, Model, load_model, model_from_yaml\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from ipywidgets import interact\n",
    "from scipy.misc import imresize, imsave\n",
    "from shutil import copyfile\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image         Id\n",
      "0  0000e88ab.jpg  w_f48451c\n",
      "1  0001f9222.jpg  w_c3d896a\n",
      "2  00029d126.jpg  w_20df2c5\n",
      "3  00050a15a.jpg  new_whale\n",
      "Number of unique classes: 5005\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.read_csv('/home/pramit/projects/data/whale_identification/train.csv')\n",
    "print(df.head(4))\n",
    "X = df.Image\n",
    "y = df.Id\n",
    "n_classes = len(np.unique(df.Id))\n",
    "print(\"Number of unique classes: {}\".format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76b7c02d3.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in X:\n",
    "    if '76b7c02d3' == str(i).split('.')[0]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def browse_images(dir_path, index_number=None, define_range=10):\n",
    "    # Read the csv file to extract info about the images\n",
    "    list_of_images = pd.read_csv(\"{}.csv\".format(dir_path)).Image\n",
    "    n = len(list_of_images)\n",
    "    if define_range > n:\n",
    "        raise ValueError(\"out of range\")\n",
    "    \n",
    "    def view_image(index):\n",
    "        # all images are of shape (700, 1050, 3)\n",
    "        im = Image.open('{}/{}'.format(dir_path, list_of_images[index]))\n",
    "        plt.imshow(im, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.show()\n",
    "    index_range = index_number if index_number else (0, define_range)\n",
    "    interact(view_image, index=(0, index_range))\n",
    "    \n",
    "\n",
    "def browse_img_dir(dir_path, define_range=10):\n",
    "    list_of_images = os.listdir(dir_path)\n",
    "    n = len(list_of_images)\n",
    "    if define_range > n:\n",
    "        raise ValueError(\"out of range\")\n",
    "    def view_image(index):\n",
    "        im = Image.open('{}{}'.format(dir_path, list_of_images[index]))\n",
    "        plt.imshow(im, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.show()\n",
    "    interact(view_image, index=(0, define_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Exploration of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504c7590c03a43639349dfa4f097fc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='index', max=3), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "browse_images('/home/pramit/projects/data/whale_identification/train', index_number=3, define_range=df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 1050, 3)\n"
     ]
    }
   ],
   "source": [
    "# image dimension of the input images\n",
    "img_width, img_height = 700, 1050\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "105*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### 1. Train 2. Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: 1000\n",
      "Validate shape: 500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train = X_train[0:1000]\n",
    "y_train = y_train[0:1000]\n",
    "\n",
    "X_validate = X_validate[0:500]\n",
    "y_validate = y_validate[0:500]\n",
    "print(\"Train shape: {}\".format(X_train.shape[0]))\n",
    "print(\"Validate shape: {}\".format(X_validate.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sample: 1000\n",
      "Number of training sample: 500\n"
     ]
    }
   ],
   "source": [
    "# Create sub-directories and copy the respective files so that it's easier to compute classification\n",
    "x_train_index = X_train.index\n",
    "print(\"Number of training sample: {}\".format(len(x_train_index)))\n",
    "x_validate_index = X_validate.index\n",
    "print(\"Number of training sample: {}\".format(len(x_validate_index)))\n",
    "\n",
    "x_train_image_names = list(X.iloc[x_train_index])\n",
    "x_validate_image_names = list(X.iloc[x_validate_index])\n",
    "\n",
    "\n",
    "import errno\n",
    "directory_train = \"/home/pramit/projects/data/whale_identification/train_set\"\n",
    "directory_validate = \"/home/pramit/projects/data/whale_identification/validate_set\"\n",
    "\n",
    "def create_folder(directory_name):\n",
    "    try:\n",
    "        os.makedirs(directory_name)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "# For train set\n",
    "create_folder(directory_train)\n",
    "# For validate set\n",
    "create_folder(directory_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy respective files to train and validate location\n",
    "def copy_files(image_name_list, src=\"/home/pramit/projects/data/whale_identification/train/\", dst=None):\n",
    "    for item in image_name_list:\n",
    "        image_name = item\n",
    "        copyfile(src+image_name, dst+image_name)\n",
    "        \n",
    "copy_files(x_train_image_names, dst=\"/home/pramit/projects/data/whale_identification/train_set/\")\n",
    "copy_files(x_validate_image_names, dst=\"/home/pramit/projects/data/whale_identification/validate_set/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(\"/home/pramit/projects/data/whale_identification/train_set/preview\")\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/home/pramit/projects/data/whale_identification/train_set/983f6c9db.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "# remember to run mkdir -p /kaggle/working/train_set/preview using the console\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='/home/pramit/projects/data/whale_identification/train_set/preview', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4666d8256a1e417699d0a35ea86d8d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='index', max=10), Output()), _dom_classes=('widget-interaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "browse_img_dir(\"/home/pramit/projects/data/whale_identification/train_set/preview/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        '/home/pramit/projects/data/whale_identification/train_set',\n",
    "        target_size=(700, 1050),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = model.predict_generator(generator, steps=63, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4965581], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('/home/pramit/projects/data/whale_identification/bottleneck_features_train.npy', bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "generator_validate = datagen.flow_from_directory(\n",
    "        '/home/pramit/projects/data/whale_identification/validate_set',\n",
    "        target_size=(700, 1050),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_validate = model.predict_generator(generator_validate, 500, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/pramit/projects/data/whale_identification/bottleneck_features_validate.npy', \n",
    "        bottleneck_features_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15880, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = np.load('/home/pramit/projects/data/whale_identification/bottleneck_features_train.npy')\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
